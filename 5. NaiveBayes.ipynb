{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\chris\\anaconda3\\lib\\site-packages (1.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"News_Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38258 entries, 0 to 38257\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    38258 non-null  object\n",
      " 1   text     38258 non-null  object\n",
      " 2   subject  38258 non-null  object\n",
      " 3   date     38258 non-null  object\n",
      " 4   Label    38258 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() \n",
    "#no further preprocessing for null values because of no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non alphabets\n",
    "remove_non_alphabets = lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
    "\n",
    "# token alphabets-only list\n",
    "tokenize = lambda x: word_tokenize(x)\n",
    "\n",
    "# assign ps to a lambda function to run on each line of value\n",
    "ps = PorterStemmer()\n",
    "stem = lambda w: [ ps.stem(x) for x in w ]\n",
    "\n",
    "# assign lemmatizer to a lambda function to run on each line of value\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : [=====] : Completed"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLASHBACK: KING OBAMA COMMUTES SENTENCES OF 22...</td>\n",
       "      <td>just make room for hillari presid obama today ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPLE’S CEO SAYS RELIGIOUS FREEDOM LAWS ARE ‘D...</td>\n",
       "      <td>the gay mafia ha a new corpor don thi is the o...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY...</td>\n",
       "      <td>In case you miss it sen harri reid R NV who an...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH NO! GUESS WHO FUNDED THE SHRINE TO TED KENNEDY</td>\n",
       "      <td>noth like polit cronyism to make your stomach ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENGHAZI PANEL CALLS HILLARY TO TESTIFY UNDER ...</td>\n",
       "      <td>doe anyon realli think hillari clinton will co...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  FLASHBACK: KING OBAMA COMMUTES SENTENCES OF 22...   \n",
       "1  APPLE’S CEO SAYS RELIGIOUS FREEDOM LAWS ARE ‘D...   \n",
       "2  WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY...   \n",
       "3  OH NO! GUESS WHO FUNDED THE SHRINE TO TED KENNEDY   \n",
       "4  BENGHAZI PANEL CALLS HILLARY TO TESTIFY UNDER ...   \n",
       "\n",
       "                                                text   subject       date  \\\n",
       "0  just make room for hillari presid obama today ...  politics  31-Mar-15   \n",
       "1  the gay mafia ha a new corpor don thi is the o...  politics  31-Mar-15   \n",
       "2  In case you miss it sen harri reid R NV who an...  politics  31-Mar-15   \n",
       "3  noth like polit cronyism to make your stomach ...  politics  31-Mar-15   \n",
       "4  doe anyon realli think hillari clinton will co...  politics  31-Mar-15   \n",
       "\n",
       "   Label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply all above methods to the column ''text\n",
    "print('Processing : [=', end='')\n",
    "data['text'] = data['text'].apply(remove_non_alphabets)\n",
    "print('=', end='')\n",
    "data['text'] = data['text'].apply(tokenize)\n",
    "print('=', end='')\n",
    "data['text'] = data['text'].apply(stem)\n",
    "print('=', end='')\n",
    "data['text'] = data['text'].apply(leammtizer)\n",
    "print('=', end='')\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x))\n",
    "print('] : Completed', end='')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : [=====] : Completed"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flashback king obama commut sentenc OF drug de...</td>\n",
       "      <td>just make room for hillari presid obama today ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appl S ceo say religi freedom law are danger T...</td>\n",
       "      <td>the gay mafia ha a new corpor don thi is the o...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>watch dirti harri reid ON hi lie about romney ...</td>\n",
       "      <td>In case you miss it sen harri reid R NV who an...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH NO guess who fund the shrine TO ted kennedi</td>\n",
       "      <td>noth like polit cronyism to make your stomach ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benghazi panel call hillari TO testifi under o...</td>\n",
       "      <td>doe anyon realli think hillari clinton will co...</td>\n",
       "      <td>politics</td>\n",
       "      <td>31-Mar-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  flashback king obama commut sentenc OF drug de...   \n",
       "1  appl S ceo say religi freedom law are danger T...   \n",
       "2  watch dirti harri reid ON hi lie about romney ...   \n",
       "3     OH NO guess who fund the shrine TO ted kennedi   \n",
       "4  benghazi panel call hillari TO testifi under o...   \n",
       "\n",
       "                                                text   subject       date  \\\n",
       "0  just make room for hillari presid obama today ...  politics  31-Mar-15   \n",
       "1  the gay mafia ha a new corpor don thi is the o...  politics  31-Mar-15   \n",
       "2  In case you miss it sen harri reid R NV who an...  politics  31-Mar-15   \n",
       "3  noth like polit cronyism to make your stomach ...  politics  31-Mar-15   \n",
       "4  doe anyon realli think hillari clinton will co...  politics  31-Mar-15   \n",
       "\n",
       "   Label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply all above methods to the column ''title\n",
    "print('Processing : [=', end='')\n",
    "data['title'] = data['title'].apply(remove_non_alphabets)\n",
    "print('=', end='')\n",
    "data['title'] = data['title'].apply(tokenize)\n",
    "print('=', end='')\n",
    "data['title'] = data['title'].apply(stem)\n",
    "print('=', end='')\n",
    "data['title'] = data['title'].apply(leammtizer)\n",
    "print('=', end='')\n",
    "data['title'] = data['title'].apply(lambda x: ' '.join(x))\n",
    "print('] : Completed', end='')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train-Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to 30 percent test data and 70 percent train data\n",
    "# labels can be seen as y, an dependent variable\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(data[\"text\"],\n",
    "                                                                        data[\"Label\"],\n",
    "                                                                        test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bag of words features' vectorizer and get features\n",
    "bow_vectorizer=CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "bow_train_features = bow_vectorizer.fit_transform(train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tfidf features' vectorizer and get features\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_corpus)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize documents for word2vec\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in test_corpus]  \n",
    "\n",
    "# build word2vec model                   \n",
    "wv_model = gensim.models.Word2Vec(tokenized_train, vector_size=200, window=60, min_count=10)\n",
    "#set the size or dimension for the word vectors\n",
    "#specify the length of the window of words taken as context \n",
    "#ignores all words with total frequency lower than 10\n",
    "\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector \n",
    "   \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "# averaged word vector features from word2vec\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=wv_model,\n",
    "                                                 num_features=200)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=wv_model,\n",
    "                                                num_features=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate our classification models based on four metrics\n",
    "# This defined function is also useful in other cases. This is comparing test_y and pred_y. \n",
    "# Both contain 1s and 0s.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    metrics_dict = dict(zip([\"accuracy\", \"precision\", \"recall\", \"f1\"], [None]*4))\n",
    "    #metrics_dict = {i:None for i in [\"accuracy\", \"precision\", \"recall\", \"f1\"]}\n",
    "    for m in metrics_dict.keys():\n",
    "        exec('''metrics_dict['{}'] = np.round(                                                    \n",
    "                        metrics.{}_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        2)'''.format(m, m))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Easy to Use Function for Train/Test/Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance   \n",
    "    '''get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)'''\n",
    "    print(metrics.classification_report(test_labels,predictions))\n",
    "    return predictions, get_metrics(true_labels=test_labels, predicted_labels=predictions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.naive_bayes import MultinomialNB # import naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier # import Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and test on BOW features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      6148\n",
      "           1       0.95      0.94      0.95      5330\n",
      "\n",
      "    accuracy                           0.95     11478\n",
      "   macro avg       0.95      0.95      0.95     11478\n",
      "weighted avg       0.95      0.95      0.95     11478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign naive bayes function to an object\n",
    "mnb = MultinomialNB()\n",
    "mnb2 = GaussianNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "mnb_bow_predictions, mnb_bow_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test on TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      6148\n",
      "           1       0.96      0.90      0.93      5330\n",
      "\n",
      "    accuracy                           0.93     11478\n",
      "   macro avg       0.94      0.93      0.93     11478\n",
      "weighted avg       0.93      0.93      0.93     11478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate naive bayes\n",
    "mnb_tfidf_predictions, mnb_tfidf_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and Test on Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      6148\n",
      "           1       0.93      0.91      0.92      5330\n",
      "\n",
      "    accuracy                           0.93     11478\n",
      "   macro avg       0.93      0.92      0.92     11478\n",
      "weighted avg       0.93      0.93      0.93     11478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate naive bayes\n",
    "mnb_avgwv_predictions, mnb_avgwv_metrics = train_predict_evaluate_model(classifier=mnb2,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
